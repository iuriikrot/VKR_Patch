"""
–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python run_all.py

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ results/.
–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤–∫–ª—é—á–∞—è —Ä–µ–∂–∏–º PatchTST) –±–µ—Ä—É—Ç—Å—è –∏–∑ config/config.yaml.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import yaml
import json
from datetime import datetime
import warnings
# –ü–æ–¥–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —à—É–º–Ω—ã–µ warnings –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫, –Ω–æ –Ω–µ –Ω–∞—à–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ (UserWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', module='pandas')
warnings.filterwarnings('ignore', module='numpy')

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "src"))

from optimization.markowitz import maximize_sharpe
from optimization.covariance import compute_covariance
from utils.forecast_metrics import aggregate_forecast_metrics

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±—ç–∫—Ç–µ—Å—Ç—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ ‚Äî —á—Ç–æ–±—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–¥–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
# –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–æ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
run_baseline1_backtest = None
run_statsforecast = None
run_patchtst_backtest = None

try:
    from backtesting.backtest import run_backtest as run_baseline1_backtest
except ImportError:
    pass

try:
    from backtesting.backtest_statsforecast import run_backtest as run_statsforecast
except ImportError:
    pass

try:
    from backtesting.backtest_patchtst import run_backtest as run_patchtst_backtest
except ImportError:
    pass

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
config_path = Path(__file__).parent / "config" / "config.yaml"
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
TRAIN_WINDOW = config['backtest']['train_window']
TEST_WINDOW = config['backtest']['test_window']
RF = config['optimization']['risk_free_rate']
CV_METHOD = config['optimization'].get('covariance', 'sample')
CONSTRAINTS = config.get('optimization', {}).get('constraints', {})
MIN_WEIGHT = CONSTRAINTS.get('min_weight', 0.0)
MAX_WEIGHT = CONSTRAINTS.get('max_weight', 1.0)
LONG_ONLY = CONSTRAINTS.get('long_only', True)
FULLY_INVESTED = CONSTRAINTS.get('fully_invested', True)
GROSS_EXPOSURE = CONSTRAINTS.get('gross_exposure')

 


def calculate_metrics(returns, rf=0.02):
    """–†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è (returns ‚Äî –º–µ—Å—è—á–Ω—ã–µ –ª–æ–≥-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏)."""
    simple_returns = np.exp(returns) - 1
    monthly_rf = (1 + rf) ** (1 / 12) - 1
    excess = simple_returns - monthly_rf

    if len(simple_returns) > 0:
        annual_return = (1 + simple_returns).prod() ** (12 / len(simple_returns)) - 1
    else:
        annual_return = 0
    annual_vol = simple_returns.std() * np.sqrt(12)
    sharpe = (excess.mean() / simple_returns.std() * np.sqrt(12)) if simple_returns.std() > 0 else 0

    cumulative = (1 + simple_returns).cumprod()
    rolling_max = cumulative.expanding().max()
    drawdown = (cumulative - rolling_max) / rolling_max
    max_drawdown = drawdown.min()

    total_return = (1 + simple_returns).prod() - 1

    # Calmar Ratio = Annual Return / |Max Drawdown|
    calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0

    return {
        'Annual Return': annual_return,
        'Annual Volatility': annual_vol,
        'Sharpe Ratio': sharpe,
        'Calmar Ratio': calmar,
        'Max Drawdown': max_drawdown,
        'Total Return': total_return,
        'Num Periods': len(returns)
    }


def compute_monthly_log_return(test_data, weights, fully_invested=True):
    """–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∑–∞ –º–µ—Å—è—Ü –ø—Ä–∏ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ —Ä–∞–∑ –≤ –º–µ—Å—è—Ü (buy-and-hold)."""
    asset_gross = np.exp(test_data.sum(axis=0).values)
    portfolio_gross = np.dot(weights, asset_gross)
    if not fully_invested:
        portfolio_gross += (1 - weights.sum())
    return np.log(portfolio_gross)


# ============================================================
# BASELINE 1: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
# ============================================================

def run_baseline1(returns, save_weights_path=None, collect_forecasts=False):
    """–ë—ç–∫—Ç–µ—Å—Ç: Œº = –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ."""
    if run_baseline1_backtest is None:
        raise ImportError("Baseline 1 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å backtest.py")
    return run_baseline1_backtest(
        returns,
        save_weights_path=save_weights_path,
        collect_forecasts=collect_forecasts
    )


# ============================================================
# BASELINE 2: StatsForecast AutoARIMA
# ============================================================

def run_baseline2(returns, save_weights_path=None, collect_forecasts=False):
    """–ë—ç–∫—Ç–µ—Å—Ç: Œº = –ø—Ä–æ–≥–Ω–æ–∑ StatsForecast AutoARIMA."""
    if run_statsforecast is None:
        raise ImportError("Baseline 2 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å statsforecast")
    return run_statsforecast(
        returns,
        save_weights_path=save_weights_path,
        collect_forecasts=collect_forecasts
    )


# ============================================================
# PATCHTST
# ============================================================

def run_patchtst(returns, save_weights_path=None, collect_forecasts=False):
    """–ë—ç–∫—Ç–µ—Å—Ç: Œº = –ø—Ä–æ–≥–Ω–æ–∑ PatchTST. –†–µ–∂–∏–º –±–µ—Ä—ë—Ç—Å—è –∏–∑ config."""
    if run_patchtst_backtest is None:
        raise ImportError("PatchTST –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å torch –∏–ª–∏ patchtst")
    return run_patchtst_backtest(
        returns,
        save_weights_path=save_weights_path,
        collect_forecasts=collect_forecasts
    )


# ============================================================
# MAIN
# ============================================================

def main():
    # –†–µ–∂–∏–º PatchTST –±–µ—Ä—ë—Ç—Å—è –∏–∑ config.yaml (fast/full)
    patchtst_mode = config['models']['patchtst'].get('mode', 'full')

    def prompt_yes_no(prompt, default=False):
        suffix = " [Y/n]: " if default else " [y/N]: "
        while True:
            ans = input(prompt + suffix).strip().lower()
            if ans == "":
                return default
            if ans in ("y", "yes", "–¥–∞", "–¥"):
                return True
            if ans in ("n", "no", "–Ω–µ—Ç", "–Ω"):
                return False
            print("–í–≤–µ–¥–∏—Ç–µ 'y' –∏–ª–∏ 'n'.")

    def prompt_models():
        print("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞:")
        print("  1 - Baseline 1 (–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)")
        print("  2 - StatsForecast AutoARIMA")
        print("  3 - PatchTST")
        while True:
            ans = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (Enter = –≤—Å–µ): ").strip()
            if ans == "":
                return {"baseline1", "baseline2", "patchtst"}
            parts = [p.strip() for p in ans.replace(" ", "").split(",") if p.strip()]
            mapping = {"1": "baseline1", "2": "baseline2", "3": "patchtst"}
            selected = {mapping[p] for p in parts if p in mapping}
            if selected:
                return selected
            print("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—ã–±–æ—Ä. –ü—Ä–∏–º–µ—Ä: 1,3")

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É results
    results_dir = Path(__file__).parent / "results"
    results_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ config/config.yaml")
    if prompt_yes_no("–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞–Ω–æ–≤–æ?", default=False):
        from data.downloader import download_and_prepare_data
        download_and_prepare_data()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data_path = Path(__file__).parent / "data" / "raw" / "log_returns.csv"
    if not data_path.exists():
        print("–û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª: {data_path}")
        print("\n–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö:")
        print("  python src/data/downloader.py")
        return

    returns = pd.read_csv(data_path, index_col=0, parse_dates=True)

    selected_models = prompt_models()

    print("=" * 60)
    print("–ó–ê–ü–£–°–ö –í–°–ï–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)
    print(f"–î–∞–Ω–Ω—ã–µ: {returns.index[0].date()} ‚Äî {returns.index[-1].date()}")
    print(f"–ê–∫—Ü–∏–π: {len(returns.columns)}")
    print(f"Train: {TRAIN_WINDOW} –¥–Ω–µ–π, Test: {TEST_WINDOW} –¥–Ω–µ–π")
    print(f"PatchTST —Ä–µ–∂–∏–º: {patchtst_mode.upper()}")
    print()

    results = {}

    total_steps = len(selected_models)
    step_num = 0

    # Baseline 1
    if "baseline1" in selected_models:
        step_num += 1
        print(f"[{step_num}/{total_steps}] Baseline 1: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ...")
        baseline1_result = run_baseline1(
            returns,
            save_weights_path=results_dir / f"baseline1_weights_{timestamp}.csv",
            collect_forecasts=True
        )
        baseline1_returns, baseline1_forecasts = baseline1_result
        forecast_metrics = aggregate_forecast_metrics(baseline1_forecasts)
        results['baseline1'] = {
            'returns': baseline1_returns,
            'metrics': calculate_metrics(baseline1_returns, rf=RF),
            'forecast_metrics': forecast_metrics,
            'forecasts': baseline1_forecasts
        }
        print(f"      Sharpe: {results['baseline1']['metrics']['Sharpe Ratio']:.2f}")
        print(f"      RMSE: {forecast_metrics['rmse']:.6f}, MAE: {forecast_metrics['mae']:.6f}, Hit Rate: {forecast_metrics['hit_rate']:.2%}")
        print()

    # Baseline 2
    if "baseline2" in selected_models:
        step_num += 1
        print(f"[{step_num}/{total_steps}] Baseline 2: StatsForecast AutoARIMA...")
        baseline2_result = run_baseline2(
            returns,
            save_weights_path=results_dir / f"statsforecast_weights_{timestamp}.csv",
            collect_forecasts=True
        )
        baseline2_returns, baseline2_forecasts = baseline2_result
        forecast_metrics = aggregate_forecast_metrics(baseline2_forecasts)
        results['baseline2'] = {
            'returns': baseline2_returns,
            'metrics': calculate_metrics(baseline2_returns, rf=RF),
            'forecast_metrics': forecast_metrics,
            'forecasts': baseline2_forecasts
        }
        print(f"      Sharpe: {results['baseline2']['metrics']['Sharpe Ratio']:.2f}")
        print(f"      RMSE: {forecast_metrics['rmse']:.6f}, MAE: {forecast_metrics['mae']:.6f}, Hit Rate: {forecast_metrics['hit_rate']:.2%}")
        print()

    # PatchTST
    if "patchtst" in selected_models:
        step_num += 1
        print(f"[{step_num}/{total_steps}] PatchTST Self-Supervised ({patchtst_mode})...")
        patchtst_result = run_patchtst(
            returns,
            save_weights_path=results_dir / f"patchtst_weights_{timestamp}.csv",
            collect_forecasts=True
        )
        patchtst_returns, patchtst_forecasts = patchtst_result
        forecast_metrics = aggregate_forecast_metrics(patchtst_forecasts)
        results['patchtst'] = {
            'returns': patchtst_returns,
            'metrics': calculate_metrics(patchtst_returns, rf=RF),
            'forecast_metrics': forecast_metrics,
            'forecasts': patchtst_forecasts
        }
        print(f"      Sharpe: {results['patchtst']['metrics']['Sharpe Ratio']:.2f}")
        print(f"      RMSE: {forecast_metrics['rmse']:.6f}, MAE: {forecast_metrics['mae']:.6f}, Hit Rate: {forecast_metrics['hit_rate']:.2%}")
        print()

    # CSV —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
    if "baseline1" in results:
        results["baseline1"]["returns"].to_csv(results_dir / f"baseline1_returns_{timestamp}.csv")
        results["baseline1"]["forecasts"].to_csv(results_dir / f"baseline1_forecasts_{timestamp}.csv", index=False)
    if "baseline2" in results:
        results["baseline2"]["returns"].to_csv(results_dir / f"statsforecast_returns_{timestamp}.csv")
        results["baseline2"]["forecasts"].to_csv(results_dir / f"statsforecast_forecasts_{timestamp}.csv", index=False)
    if "patchtst" in results:
        results["patchtst"]["returns"].to_csv(results_dir / f"patchtst_returns_{timestamp}.csv")
        results["patchtst"]["forecasts"].to_csv(results_dir / f"patchtst_forecasts_{timestamp}.csv", index=False)

    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ + –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤)
    comparison_data = {}
    if "baseline1" in results:
        merged = {**results['baseline1']['metrics'], **{f'Forecast_{k}': v for k, v in results['baseline1']['forecast_metrics'].items()}}
        comparison_data['Baseline 1 (Hist Mean)'] = merged
    if "baseline2" in results:
        merged = {**results['baseline2']['metrics'], **{f'Forecast_{k}': v for k, v in results['baseline2']['forecast_metrics'].items()}}
        comparison_data['Baseline 2 (StatsForecast)'] = merged
    if "patchtst" in results:
        merged = {**results['patchtst']['metrics'], **{f'Forecast_{k}': v for k, v in results['patchtst']['forecast_metrics'].items()}}
        comparison_data['PatchTST'] = merged
    comparison = pd.DataFrame(comparison_data).T
    comparison.to_csv(results_dir / f"comparison_{timestamp}.csv")

    # JSON —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    metrics_json = {
        'timestamp': timestamp,
        'config': {
            'train_window': TRAIN_WINDOW,
            'test_window': TEST_WINDOW,
            'risk_free_rate': RF,
            'patchtst_mode': patchtst_mode
        },
        'metrics': {},
        'forecast_metrics': {}
    }
    if "baseline1" in results:
        metrics_json['metrics']['baseline1'] = results['baseline1']['metrics']
        metrics_json['forecast_metrics']['baseline1'] = results['baseline1']['forecast_metrics']
    if "baseline2" in results:
        metrics_json['metrics']['baseline2'] = results['baseline2']['metrics']
        metrics_json['forecast_metrics']['baseline2'] = results['baseline2']['forecast_metrics']
    if "patchtst" in results:
        metrics_json['metrics']['patchtst'] = results['patchtst']['metrics']
        metrics_json['forecast_metrics']['patchtst'] = results['patchtst']['forecast_metrics']
    with open(results_dir / f"metrics_{timestamp}.json", 'w') as f:
        json.dump(metrics_json, f, indent=2, default=str)

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("=" * 60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´: –ü–û–†–¢–§–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò")
    print("=" * 60)
    labels = []
    if "baseline1" in results:
        labels.append(("baseline1", "Baseline 1"))
    if "baseline2" in results:
        labels.append(("baseline2", "StatsF"))
    if "patchtst" in results:
        labels.append(("patchtst", "PatchTST"))

    header = f"\n{'–ú–µ—Ç—Ä–∏–∫–∞':<25}" + "".join([f"{label:>12}" for _, label in labels])
    print(header)
    print("-" * (25 + 12 * len(labels)))
    for metric in ['Annual Return', 'Annual Volatility', 'Sharpe Ratio', 'Calmar Ratio', 'Max Drawdown', 'Total Return']:
        if 'Ratio' in metric:
            row = f"{metric:<25}" + "".join(
                [f"{results[key]['metrics'][metric]:>12.2f}" for key, _ in labels]
            )
        else:
            row = f"{metric:<25}" + "".join(
                [f"{results[key]['metrics'][metric]:>12.2%}" for key, _ in labels]
            )
        print(row)

    # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    print()
    print("=" * 60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´: –ú–ï–¢–†–ò–ö–ò –ü–†–û–ì–ù–û–ó–û–í")
    print("=" * 60)
    header = f"\n{'–ú–µ—Ç—Ä–∏–∫–∞':<25}" + "".join([f"{label:>12}" for _, label in labels])
    print(header)
    print("-" * (25 + 12 * len(labels)))
    for metric, fmt in [('rmse', '.6f'), ('mae', '.6f'), ('hit_rate', '.2%')]:
        row = f"{metric.upper():<25}" + "".join(
            [f"{results[key]['forecast_metrics'][metric]:>12{fmt}}" for key, _ in labels]
        )
        print(row)

    print()
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_dir}/")
    print(f"  - comparison_{timestamp}.csv")
    print(f"  - metrics_{timestamp}.json")
    print(f"  - *_returns_{timestamp}.csv")
    print(f"  - *_forecasts_{timestamp}.csv")
    print(f"  - *_weights_{timestamp}.csv")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    try:
        import matplotlib.pyplot as plt

        print("\n" + "=" * 60)
        print("–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 60)

        # –ì—Ä–∞—Ñ–∏–∫ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        fig, ax = plt.subplots(figsize=(14, 7))

        for key, label in labels:
            simple_returns = np.exp(results[key]['returns']) - 1
            cumulative = (1 + simple_returns).cumprod()
            ax.plot(cumulative.index, cumulative.values, label=label, linewidth=2)

        ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π', fontsize=14, fontweight='bold')
        ax.set_xlabel('–î–∞—Ç–∞')
        ax.set_ylabel('–†–æ—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∞ ($1 ‚Üí $X)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_path = results_dir / f"cumulative_returns_{timestamp}.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"\n–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")

        plt.show()

        # –ò—Ç–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        print("\n–†–æ—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∞ ($1 ‚Üí $X):")
        for key, label in labels:
            simple_returns = np.exp(results[key]['returns']) - 1
            cumulative = (1 + simple_returns).cumprod()
            print(f"  {label}: $1 ‚Üí ${cumulative.iloc[-1]:.2f}")

    except ImportError:
        print("\n–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (matplotlib –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    except Exception as e:
        print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

    # –ê–Ω–∞–ª–∏–∑ –≤–µ—Å–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å baseline1 –∏ patchtst)
    if "baseline1" in results and "patchtst" in results:
        analyze_weight_differences(results_dir, timestamp, results)


def analyze_weight_differences(results_dir, timestamp, results):
    """
    –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –≤ –≤–µ—Å–∞—Ö –º–µ–∂–¥—É Baseline1 –∏ PatchTST.
    –û–±—ä—è—Å–Ω—è–µ—Ç, –ø–æ—á–µ–º—É PatchTST –∏–º–µ–µ—Ç –º–µ–Ω—å—à—É—é –ø—Ä–æ—Å–∞–¥–∫—É.
    """
    print("\n" + "=" * 60)
    print("–ê–ù–ê–õ–ò–ó –í–ï–°–û–í: –ü–û–ß–ï–ú–£ PATCHTST –ò–ú–ï–ï–¢ –ú–ï–ù–¨–®–£–Æ –ü–†–û–°–ê–î–ö–£?")
    print("=" * 60)

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        b1_weights_path = results_dir / f"baseline1_weights_{timestamp}.csv"
        pt_weights_path = results_dir / f"patchtst_weights_{timestamp}.csv"

        if not b1_weights_path.exists() or not pt_weights_path.exists():
            print("–§–∞–π–ª—ã –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑")
            return

        b1_weights = pd.read_csv(b1_weights_path, index_col=0, parse_dates=True)
        pt_weights = pd.read_csv(pt_weights_path, index_col=0, parse_dates=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–∏–æ–¥–æ–≤ –ø—Ä–æ—Å–∞–¥–æ–∫
        b1_returns = results['baseline1']['returns']
        pt_returns = results['patchtst']['returns']

        # 1. –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ø-5 —Ö—É–¥—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è Baseline1
        print("\nüìâ TOP-5 –•–£–î–®–ò–• –ü–ï–†–ò–û–î–û–í –î–õ–Ø BASELINE1:")
        print("-" * 60)

        worst_periods = b1_returns.nsmallest(5)
        analysis_results = []

        for date, b1_ret in worst_periods.items():
            pt_ret = pt_returns.get(date, np.nan)
            if date not in b1_weights.index or date not in pt_weights.index:
                continue

            b1_w = b1_weights.loc[date]
            pt_w = pt_weights.loc[date]
            diff = pt_w - b1_w

            # –¢–æ–ø –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤
            increased = diff.nlargest(3)
            decreased = diff.nsmallest(3)

            print(f"\n{date.strftime('%Y-%m-%d')}: B1={b1_ret:.2%}, PT={pt_ret:.2%} (—Ä–∞–∑–Ω–∏—Ü–∞: {pt_ret-b1_ret:+.2%})")
            print(f"  PatchTST —É–≤–µ–ª–∏—á–∏–ª: {', '.join([f'{t}:{v:+.1%}' for t, v in increased.items()])}")
            print(f"  PatchTST —É–º–µ–Ω—å—à–∏–ª: {', '.join([f'{t}:{v:+.1%}' for t, v in decreased.items()])}")

            analysis_results.append({
                'date': date,
                'b1_return': b1_ret,
                'pt_return': pt_ret,
                'diff': pt_ret - b1_ret,
                'increased': dict(increased),
                'decreased': dict(decreased)
            })

        # 2. –°—Ä–µ–¥–Ω–∏–µ –≤–µ—Å–∞ –ø–æ –∞–∫—Ç–∏–≤–∞–º
        print("\n\nüìä –°–†–ï–î–ù–ò–ï –†–ê–ó–õ–ò–ß–ò–Ø –í –í–ï–°–ê–• (PatchTST - Baseline1):")
        print("-" * 60)

        avg_diff = (pt_weights - b1_weights).mean()
        avg_diff_sorted = avg_diff.sort_values()

        print("\nPatchTST –¥–µ—Ä–∂–∏—Ç –ú–ï–ù–¨–®–ï (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ):")
        for ticker, diff in avg_diff_sorted.head(5).items():
            print(f"  {ticker}: {diff:+.1%}")

        print("\nPatchTST –¥–µ—Ä–∂–∏—Ç –ë–û–õ–¨–®–ï:")
        for ticker, diff in avg_diff_sorted.tail(5).items():
            print(f"  {ticker}: {diff:+.1%}")

        # 3. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤–µ—Å–æ–≤ (–∫–∞–∫ —á–∞—Å—Ç–æ –º–µ–Ω—è—é—Ç—Å—è)
        print("\n\nüìà –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ –í–ï–°–û–í (–Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –º–µ–Ω—è—é—Ç—Å—è):")
        print("-" * 60)

        b1_weight_vol = b1_weights.diff().abs().mean().mean()
        pt_weight_vol = pt_weights.diff().abs().mean().mean()

        print(f"  Baseline1 avg weight change: {b1_weight_vol:.2%}")
        print(f"  PatchTST avg weight change:  {pt_weight_vol:.2%}")
        print(f"  PatchTST –º–µ–Ω—è–µ—Ç –≤–µ—Å–∞ –≤ {pt_weight_vol/b1_weight_vol:.2f}x —á–∞—â–µ")

        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–∞–π–ª
        analysis_path = results_dir / f"weight_analysis_{timestamp}.txt"
        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.write("–ê–ù–ê–õ–ò–ó –í–ï–°–û–í: –ü–û–ß–ï–ú–£ PATCHTST –ò–ú–ï–ï–¢ –ú–ï–ù–¨–®–£–Æ –ü–†–û–°–ê–î–ö–£?\n")
            f.write("=" * 60 + "\n\n")

            f.write("1. TOP-5 –•–£–î–®–ò–• –ü–ï–†–ò–û–î–û–í –î–õ–Ø BASELINE1\n")
            f.write("-" * 40 + "\n")
            for r in analysis_results:
                f.write(f"\n{r['date'].strftime('%Y-%m-%d')}: B1={r['b1_return']:.2%}, PT={r['pt_return']:.2%}\n")
                f.write(f"  –£–≤–µ–ª–∏—á–∏–ª: {r['increased']}\n")
                f.write(f"  –£–º–µ–Ω—å—à–∏–ª: {r['decreased']}\n")

            f.write("\n\n2. –°–†–ï–î–ù–ò–ï –†–ê–ó–õ–ò–ß–ò–Ø –í –í–ï–°–ê–•\n")
            f.write("-" * 40 + "\n")
            f.write("\nPatchTST –¥–µ—Ä–∂–∏—Ç –ú–ï–ù–¨–®–ï:\n")
            for ticker, diff in avg_diff_sorted.head(5).items():
                f.write(f"  {ticker}: {diff:+.1%}\n")
            f.write("\nPatchTST –¥–µ—Ä–∂–∏—Ç –ë–û–õ–¨–®–ï:\n")
            for ticker, diff in avg_diff_sorted.tail(5).items():
                f.write(f"  {ticker}: {diff:+.1%}\n")

            f.write(f"\n\n3. –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ –í–ï–°–û–í\n")
            f.write("-" * 40 + "\n")
            f.write(f"Baseline1: {b1_weight_vol:.2%}\n")
            f.write(f"PatchTST:  {pt_weight_vol:.2%}\n")
            f.write(f"Ratio: {pt_weight_vol/b1_weight_vol:.2f}x\n")

            f.write("\n\n4. –í–´–í–û–î–´\n")
            f.write("-" * 40 + "\n")
            f.write("PatchTST –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –º–µ–Ω—å—à–µ–π –ø—Ä–æ—Å–∞–¥–∫–∏ –∑–∞ —Å—á—ë—Ç:\n")
            f.write("- –°–Ω–∏–∂–µ–Ω–∏—è –¥–æ–ª–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö tech/growth –∞–∫—Ü–∏–π\n")
            f.write("- –£–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–æ–ª–∏ –∑–∞—â–∏—Ç–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤ (utilities, consumer staples)\n")
            f.write("- –ë–æ–ª–µ–µ —á–∞—Å—Ç–æ–π —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ (–±—ã—Å—Ç—Ä–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫)\n")

        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {analysis_path}")

    except Exception as e:
        print(f"\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–µ—Å–æ–≤: {e}")


if __name__ == "__main__":
    main()
